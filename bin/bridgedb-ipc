#!/usr/bin/env node

var _ = require("lodash");
var crypto = require("crypto");
var csv = require("csv-streamify");
var fs = require("fs");
var path = require("path");
var BridgeDb = require("../es5/BridgeDb").BridgeDb;
var hl = require("highland");
var ndjson = require("ndjson");
var npmPackage = require("../package.json");
var program = require("commander");
var Rx = require("rx-extra");
require("../es5/spinoffs/pipeToStdout");
var VError = require("verror");
var ipc = require('node-ipc');

// time to wait for no new calls to xrefs() before we
// batch up all calls in the queue and send to xrefsBatch()
var XREF_REQUEST_DEBOUNCE_TIME = 100; // ms
var IPC_SERVER_PROCESS_NAME = 'bridgeDbProcess';
ipc.config.retry = 250;
ipc.config.stopRetrying = 3;
ipc.config.silent = true;
// TODO look at "path" in ipc.serve(path,callback):
// https://www.npmjs.com/package/node-ipc#serve
// We can maybe use that instead of IPC_SERVER_ON_FILE
var IPC_SERVER_ON_FILE = path.join(__dirname, '.ipc-started');

function makeXrefsRequest(organism, dbConventionalName, dbId) {
  var primaryBridgeDbProcess = !fs.existsSync(IPC_SERVER_ON_FILE);
  var xrefsResponseQueue = new Rx.Subject();

  if (primaryBridgeDbProcess) {
    fs.writeFileSync(IPC_SERVER_ON_FILE, '');
    ipc.config.id = IPC_SERVER_PROCESS_NAME;
    ipc.serve(function() {
      var bridgeDb = new BridgeDb();
      bridgeDb
        .xrefs(organism, dbConventionalName, dbId)
        .subscribe(xrefsResponseQueue);

      var endSignal = new Rx.Subject();
      var debounceSignal = Rx.Observable.fromEvent(ipc.server, 'xrefsRequest')
        .debounceTime(
          XREF_REQUEST_DEBOUNCE_TIME
        )
        .first();

      ipc.server.on('xrefsRequest', function(xrefsRequest, socket) {
        bridgeDb
          .xrefs(xrefsRequest.organism, xrefsRequest.dbConventionalName, xrefsRequest.dbId)
          .subscribe(function(response) {
            ipc.server.emit(socket, 'xrefsResponse', response);
            endSignal.next();
          }, function(err) {
            ipc.server.emit(socket, 'err', err);
            endSignal.error(err);
          }, function() {
            ipc.server.emit(socket, 'end');
            endSignal.complete();
          });
      });

      endSignal
        .skipUntil(debounceSignal)
        .first()
        .subscribe(function(data) {
        }, function(err) {
          throw  err;
        }, function() {
          ipc.server.stop();
          fs.unlinkSync(IPC_SERVER_ON_FILE);
          console.warn('bridgeDb CLI server stopped...');
        });

      debounceSignal.subscribe();
    });
    ipc.server.start();
  } else {
    ipc.config.id = IPC_SERVER_PROCESS_NAME + new Date().toISOString();
    ipc.connectTo(IPC_SERVER_PROCESS_NAME, function() {
      ipc.of[IPC_SERVER_PROCESS_NAME].on(
        'connect',
        function(){
          ipc.of[IPC_SERVER_PROCESS_NAME].emit('xrefsRequest', {
            organism: organism,
            dbConventionalName: dbConventionalName,
            dbId: dbId
          });

          ipc.of[IPC_SERVER_PROCESS_NAME].on('xrefsResponse', function(xrefsResponse, socket) {
            xrefsResponseQueue.next(xrefsResponse);
          });
          ipc.of[IPC_SERVER_PROCESS_NAME].on('err', function(err, socket) {
            xrefsResponseQueue.err(err);
          });
          ipc.of[IPC_SERVER_PROCESS_NAME].on('end', function() {
            xrefsResponseQueue.complete();
            ipc.disconnect(IPC_SERVER_PROCESS_NAME);
          });
        });
    });
  }

  return xrefsResponseQueue;
}

program
  .version(npmPackage.version)
  .description("CLI client for BridgeDb ID mapping webservice.");

program.on("--help", function() {
  console.log("  Examples:");
  console.log();
  console.log("    Display xrefs in command line:");
  console.log("    $ bridgedb xrefs 'Homo sapiens' 'Entrez Gene' 1234");
  console.log();
  console.log("    Save multiple xrefs to new file:");
  console.log(
    [
      "    $ cat test/dbNamesAndIds.csv | bridgedb xrefsBatch ",
      "--organism='Homo sapiens' > ./xrefs.json"
    ].join("")
    /* TODO why doesn't the following work?
    [
      "    $ bridgedb xrefsBatch ",
      "--organism='Homo sapiens' --dbConventionalName='Entrez Gene' ",
      "< ./test/dbNamesAndIds.csv > ./xrefs.json"
    ].join("")
    //*/
  );
});

/*
echo '[{"dbId": "1234", "dbConventionalName": "Entrez Gene"},{"dbId": "1235", "dbConventionalName": "Entrez Gene"}]' | jq -rc .[] | ./bin/bridgedb enrichBatch " Homo sapiens" dbConventionalName dbId

cat data.txt | jq -rc . | bin/bridgedb enrichBatch "Homo sapiens" dbConventionalName dbId

echo '[{"dbId": "1234", "dbConventionalName": "Entrez Gene"},{"dbId": "1235", "dbConventionalName": "Entrez Gene"}]' | jq -rc .[] | ./bin/bridgedb enrich "Homo sapiens" dbConventionalName dbId ncbigene ensembl wikidata
//*/
program
  .command(
    "enrich <organism> <dbConventionalNameProperty> <dbIdProperty> [unificationDataSources...]"
  )
  .action(function(
    organism,
    dbConventionalNameProperty,
    dbIdProperty,
    unificationDataSources
  ) {
    var bridgeDb = new BridgeDb();

    if (unificationDataSources.length === 0) {
      unificationDataSources = "*";
    }

    hl(process.stdin)
      .through(ndjson.parse())
      .flatMap(function(input) {
        var outStream = hl();

        var dbConventionalName = input[dbConventionalNameProperty];
        var dbId = input[dbIdProperty];

        bridgeDb
          .xrefExists(organism, dbConventionalName, dbId)
          .mergeMap(function(exists) {
            return exists
              ? bridgeDb
                  .xrefs(organism, dbConventionalName, dbId)
                  .filter(function(xref) {
                    return (
                      unificationDataSources === "*" ||
                      unificationDataSources.indexOf(
                        xref.isDataItemIn.preferredPrefix
                      ) > -1
                    );
                  })
                  .map(function(xref) {
                    var preferredPrefix = xref.isDataItemIn.preferredPrefix;
                    var dbId = xref.dbId;
                    input[preferredPrefix] = dbId;
                    input.type = input.type || [];
                    input.type.push(preferredPrefix + ":" + dbId);
                    return input;
                  })
              : Rx.Observable.empty();
          })
          .subscribe(
            null,
            function(err) {
              throw err;
              //outStream.write(err);
              outStream.error(err);
            },
            function() {
              outStream.write(input);
              outStream.end();
            }
          );
        return outStream;
      })
      .through(ndjson.serialize())
      .pipe(process.stdout);
  });

// npm run compile:es5 && ./bin/bridgedb xrefs 'Homo sapiens' 'Entrez Gene' '1234'
//
// cat test/dbNamesAndIds.csv | while read ln; do xrefDb=`echo $ln | sed s/,.*//g`; xrefId=`echo $ln | sed 's/^.*,//g'`; echo "$xrefDb" "$xrefId"; ./bin/bridgedb xrefs "Homo sapiens" "$xrefDb" "$xrefId"; done

// cat test/dbNamesAndIds.csv | while read ln; do xrefDb=`echo $ln | sed s/,.*//g`; xrefId=`echo $ln | sed 's/^.*,//g'`; echo "$xrefDb" "$xrefId"; ./bin/bridgedb xrefs "Homo sapiens" "$xrefDb" "$xrefId" | jq ". | .dbId | {\"$xrefId\": .}" | tee $xrefId.tsv & done
program
  .command("xrefs <organism> <dbConventionalName> <dbId>")
  .action(function(organism, dbConventionalName, dbId) {
    var serialize = ndjson.serialize();
    makeXrefsRequest(organism, dbConventionalName, dbId)
      .throughNodeStream(serialize)
      /*
      .map(function(x) {
        return JSON.stringify(x);
      })
      //*/
      //.do(console.warn)
      .pipeToStdout();
  });
// npm run compile:es5 && ./bin/bridgedb dataSource 'Entrez Gene'
// npm run compile:es5 && ./bin/bridgedb dataSource 'Entrez Gene'
/*
cat ../gpml2pvjson-js/test/expected/WP481_94171.json | jq '.entitiesById[] | select(has("dbConventionalName") and .kaavioType=="SingleFreeNode") | .dbConventionalName+"\t"+.dbId'
*/
program
  .command("datasource <input> [as]")
  .option(
    "--format [string]",
    'Column format to return when identifying a data source name format: term or iri. Default: "term"'
  )
  .action(function(input, as, options) {
    var format = !!options['format'] ? options['format'] : 'term';
    var serialize = ndjson.serialize();
    var bridgeDb = new BridgeDb();
    if (!!as) {
        bridgeDb
          .convertDataSourceNameTo(as, input)
          .throughNodeStream(serialize)
          .pipeToStdout();
    } else {
      if (format === 'term') {
        bridgeDb
          .dataSourceNameToColumnTerm(input)
          .throughNodeStream(serialize)
          .pipeToStdout();
      } else {
        bridgeDb
          .dataSourceNameToColumnIri(input)
          .throughNodeStream(serialize)
          .pipeToStdout();
      }
    }
  });

/*
Compile, if needed:
npm run compile:es5

Run it, as in one of the following examples:

echo $'1234\n1235\n' | ./bin/bridgedb xrefsBatch --organism 'Homo sapiens' --dbConventionalName 'Entrez Gene'

./bin/bridgedb xrefsBatch --organism 'Homo sapiens' --dbConventionalName 'Entrez Gene' <<< $'1234\n1235\n'

echo $'dbId\n1234\n1235\n' | ./bin/bridgedb xrefsBatch --organism 'Homo sapiens' --dbConventionalName 'Entrez Gene' --headers=true

cat test/dbIds.csv | ./bin/bridgedb xrefsBatch --organism="Homo sapiens" --dbConventionalName="Entrez Gene"

./bin/bridgedb xrefsBatch --organism="Homo sapiens" < test/dbNamesAndIds.csv

cat test/dbNamesAndIds.csv | ./bin/bridgedb xrefsBatch --organism="Homo sapiens"
*/
program
  .command(
    "xrefsBatch [dbIdColumn] [dbConventionalNameColumn] [organismColumn]"
  )
  .description("Get xrefs for entities in a delimited file (CSV, TSV, etc.)")
  .option(
    "-d, --delimiter [string]",
    'Delimiter for file, e.g., "," or "\t". Default: ","'
  )
  .option(
    "--organism [string]",
    'If organismColumn not specified, set organism, e.g., "Homo sapiens"'
  )
  .option(
    "--dbConventionalName [string]",
    'If dbConventionalNameColumn not specified, set dbConventionalName, e.g., "Entrez Gene"'
  )
  .option("--headers [boolean]", "First row of file is headers")
  .action(function(
    dbIdColumnStr,
    dbConventionalNameColumnStr,
    organismColumnStr,
    options
  ) {
    var organismOption = options.organism;
    var dbConventionalNameOption = options.dbConventionalName;
    var headersOption = options.hasOwnProperty("headers")
      ? Boolean(options.headers)
      : false;
    var delimiterOption = options.delimiter || ",";
    var newlineOption = options.newline || "\n"; // newline character (use \r\n for CRLF files)
    var quoteOption = options.quote || '"';

    var organismColumn = typeof organismColumnStr !== "undefined"
      ? parseInt(organismColumnStr)
      : typeof organismOption === "undefined" ? 0 : null;

    var dbConventionalNameColumn = typeof dbConventionalNameColumnStr !==
      "undefined"
      ? parseInt(dbConventionalNameColumnStr)
      : typeof dbConventionalNameOption === "undefined"
        ? organismColumn === null ? 0 : organismColumn + 1
        : null;

    var dbIdColumn = typeof dbIdColumnStr !== "undefined"
      ? parseInt(dbIdColumnStr)
      : typeof dbIdOption === "undefined"
        ? dbConventionalNameColumn === null ? 0 : dbConventionalNameColumn + 1
        : null;

    var bridgeDb = new BridgeDb();

    var parser = csv({
      delimiter: delimiterOption,
      newline: newlineOption,
      quote: quoteOption,
      objectMode: true
    });

    var serialize = ndjson.serialize();

    Rx.Observable
      .fromNodeReadableStream(
        hl(process.stdin).through(parser).drop(headersOption ? 1 : 0)
      )
      .map(function(row) {
        return {
          organism: typeof organismOption !== "undefined"
            ? organismOption
            : row[organismColumn],
          dbConventionalName: typeof dbConventionalNameOption !== "undefined"
            ? dbConventionalNameOption
            : row[dbConventionalNameColumn],
          dbId: typeof dbIdOption !== "undefined" ? dbIdOption : row[dbIdColumn]
        };
      })
      .mergeMap(function(x) {
        var organism = x.organism;
        var dbConventionalName = x.dbConventionalName;
        var dbId = x.dbId;
        return bridgeDb
          .dataSourceProperties(dbConventionalName)
          .mergeMap(function(dataSource) {
            if (!dataSource || !dataSource.id) {
              return Rx.Observable.throw(
                new Error(`Cannot process "${dbConventionalName}:${dbId}"`)
              );
            }
            var id = dataSource.id + dbId;
            return bridgeDb
              .xrefs(organism, dbConventionalName, dbId)
              .toArray()
              .map(function(xrefs) {
                return {
                  id: id,
                  dbConventionalName: dbConventionalName,
                  dbId: dbId,
                  organism: organism,
                  xrefs: xrefs
                };
              });
          });
      })
      .map(function(result) {
        return '\t' + result.id + '\n\t\t' + result.xrefs.map(function(xref) {
          return [xref.dataSource, xref.dbId].join('\t');
        }).join('\n\t\t') + '\n'
      })
      //.throughNodeStream(serialize)
      .pipeToStdout();

//          .mergeMap(function(dataSource) {
//            if (!dataSource || !dataSource.id) {
//              return Rx.Observable.throw(
//                new Error(`Cannot process "${dbConventionalName}:${dbId}"`)
//              );
//            }
//            var id = dataSource.id + dbId;
//            return bridgeDb
//              .xrefs(organism, dbConventionalName, dbId)
//            /*
//            .map(function(xref) {
//              return [xref.dataSource, xref.dbId].join('\t');
//            })
//              .toArray()
//              .map(function(xrefStrings) {
//                return xrefStrings.join('\n');
//              });
//            //*/
//            //*
//              .toArray()
//              .map(function(xrefs) {
//                return {
//                  id: id,
//                  //dbConventionalName: dbConventionalName,
//                  //dbId: dbId,
//                  //organism: organism,
//                  xrefs: xrefs
//                };
//              });
//            //*/
//          });
  });

program.parse(process.argv);
